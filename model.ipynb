{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as tt\n",
    "from torchvision.datasets import ImageFolder\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels = 3\n",
    "n_epochs=33\n",
    "max_lr = 0.001\n",
    "weight_decay = 1e-4\n",
    "image_size=64\n",
    "batch_size = 80\n",
    "drop_rate = 0.6\n",
    "\n",
    "train_dir = 'data/cats/train'\n",
    "valid_dir = 'data/cats/valid'\n",
    "test_image_path = 'data/cats/input/image1.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation for the training and valid\n",
    "added a horizontal flip for the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data transformations\n",
    "transform = tt.Compose([\n",
    "    tt.RandomHorizontalFlip(),\n",
    "    tt.RandomRotation(10),\n",
    "    tt.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    tt.RandomResizedCrop((image_size, image_size)),\n",
    "    tt.Resize((image_size, image_size)),\n",
    "    tt.ToTensor(),\n",
    "    tt.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "])\n",
    "\n",
    "transformv = tt.Compose([\n",
    "    tt.Resize((image_size, image_size)),\n",
    "    tt.ToTensor(),\n",
    "    tt.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "])\n",
    "\n",
    "# Load datasets\n",
    "train_ds = ImageFolder(train_dir, transform=transform)\n",
    "valid_ds = ImageFolder(valid_dir, transform=transformv)\n",
    "\n",
    "# Data loaders\n",
    "train_loader = DataLoader(train_ds, batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_ds, batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot a batch of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: ['Angry', 'Disgusted', 'Happy', 'Normal', 'Sad', 'Scared', 'Surprised']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def show_batch(dl):\n",
    "    for images, labels in dl:\n",
    "        plt.figure(figsize=(12, 12))\n",
    "        plt.axis('off')\n",
    "        plt.imshow(make_grid(images, nrow=10).permute(1, 2, 0))\n",
    "        plt.show()\n",
    "        break\n",
    "\n",
    "print(\"Labels:\", train_ds.classes)\n",
    "show_batch(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CNN block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvolutionBlock(in_channels, out_channels, pool=False):\n",
    "    layers = [\n",
    "    nn.Conv2d(in_channels,out_channels,kernel_size=3, stride=1, padding=1),\n",
    "    nn.BatchNorm2d(out_channels),\n",
    "    nn.ReLU(inplace=True),\n",
    "    ]\n",
    "    if pool: layers.append(nn.MaxPool2d(2)) #change\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "class CatEmotionCNN(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super(CatEmotionCNN, self).__init__()\n",
    "\n",
    "        self.input = ConvolutionBlock(in_channels, 64)\n",
    "\n",
    "        self.conv1 = ConvolutionBlock(64, 64, pool=True)\n",
    "        self.res1 = nn.Sequential(ConvolutionBlock(64, 32), ConvolutionBlock(32, 64))\n",
    "        self.drop1 = nn.Dropout(drop_rate)\n",
    "        \n",
    "        self.conv2 = ConvolutionBlock(64, 64, pool=True)\n",
    "        self.res2 = nn.Sequential(ConvolutionBlock(64, 32), ConvolutionBlock(32, 64))\n",
    "        self.drop2 = nn.Dropout(drop_rate)\n",
    "        \n",
    "        self.conv3 = ConvolutionBlock(64, 64, pool=True)\n",
    "        self.res3 = nn.Sequential(ConvolutionBlock(64, 32), ConvolutionBlock(32, 64))\n",
    "        self.drop3 = nn.Dropout(drop_rate)\n",
    "        \n",
    "        self.classifier = nn.Sequential(nn.AdaptiveAvgPool2d((1, 1)), \n",
    "                                        nn.Flatten(),\n",
    "                                        nn.Linear(64,num_classes ))\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.input(x)\n",
    "\n",
    "        out = self.conv1(out)\n",
    "        out = self.res1(out) + out\n",
    "        out = self.drop1(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.res2(out) + out\n",
    "        out = self.drop2(out)\n",
    "        \n",
    "        out = self.conv3(out)\n",
    "        out = self.res3(out) + out\n",
    "        out = self.drop3(out)\n",
    "        return self.classifier(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Optimizer and model loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatEmotionCNN(in_channels, num_classes=len(train_ds.classes)).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=max_lr, weight_decay=weight_decay)\n",
    "\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "train_accuracies = []\n",
    "valid_accuracies = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, valid_loader, epochs=n_epochs):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct_train += (preds == labels).sum().item()\n",
    "            total_train += labels.size(0)\n",
    "\n",
    "        train_acc = correct_train / total_train\n",
    "        train_losses.append(train_loss / len(train_loader))\n",
    "        train_accuracies.append(train_acc)\n",
    "\n",
    "        model.eval()\n",
    "        valid_loss = 0\n",
    "        correct_valid = 0\n",
    "        total_valid = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in valid_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                valid_loss += loss.item()\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                correct_valid += (preds == labels).sum().item()\n",
    "                total_valid += labels.size(0)\n",
    "\n",
    "        valid_acc = correct_valid / total_valid\n",
    "        valid_losses.append(valid_loss / len(valid_loader))\n",
    "        valid_accuracies.append(valid_acc)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_losses[-1]:.4f}, Valid Loss: {valid_losses[-1]:.4f}, Train Acc: {train_acc:.4f}, Valid Acc: {valid_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training loss, accuracy and confusion matrix plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics():\n",
    "    epochs_range = range(len(train_losses))\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Loss plot\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, train_losses, label='Training Loss')\n",
    "    plt.plot(epochs_range, valid_losses, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Training and Validation Loss')\n",
    "\n",
    "    # Accuracy plot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, train_accuracies, label='Training Accuracy')\n",
    "    plt.plot(epochs_range, valid_accuracies, label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Confusion matrix\n",
    "def plot_confusion_matrix(model, valid_loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in valid_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    cm = confusion_matrix(all_labels, all_preds, labels=range(len(valid_ds.classes)))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=valid_ds.classes)\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### misc: \n",
    "save model, random prediction from valid folder and input image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_model(model, path):\n",
    "    torch.save(model.state_dict(), path)\n",
    "\n",
    "def show_random_prediction(model, valid_ds):\n",
    "    model.eval()\n",
    "    idx = random.randint(0, len(valid_ds) - 1)\n",
    "    image, true_label = valid_ds[idx]\n",
    "    image = image.unsqueeze(0).to(device)\n",
    "    true_label_name = valid_ds.classes[true_label]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred = model(image)\n",
    "        predicted_label = torch.argmax(pred, dim=1).item()\n",
    "        predicted_label_name = valid_ds.classes[predicted_label]\n",
    "\n",
    "    plt.imshow(image.cpu().squeeze().permute(1, 2, 0) * 0.5 + 0.5)\n",
    "    plt.title(f\"True: {true_label_name}, Predicted: {predicted_label_name}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def test_single_image(model, image_path):\n",
    "    model.eval()\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = transformv(image).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred = model(image)\n",
    "        predicted_label = torch.argmax(pred, dim=1).item()\n",
    "        predicted_label_name = train_ds.classes[predicted_label]\n",
    "\n",
    "    plt.imshow(image.cpu().squeeze().permute(1, 2, 0) * 0.5 + 0.5)\n",
    "    plt.title(f\"Predicted: {predicted_label_name}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_model(model, train_loader, valid_loader) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics()\n",
    "plot_confusion_matrix(model, valid_loader)\n",
    "test_single_image(model, test_image_path)\n",
    "show_random_prediction(model, valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
